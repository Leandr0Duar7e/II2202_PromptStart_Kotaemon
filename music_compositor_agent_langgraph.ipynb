{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Music Compositor using LangGraph\n",
    "\n",
    "## Overview\n",
    "This tutorial demonstrates how to build an AI-powered music composition system using LangGraph, a framework for creating workflows with language models. The system generates musical compositions based on user input, leveraging various components to create melody, harmony, rhythm, and style adaptations.\n",
    "\n",
    "## Motivation\n",
    "Creating music programmatically is a fascinating intersection of artificial intelligence and artistic expression. This project aims to explore how language models and graph-based workflows can be used to generate coherent musical pieces, providing a unique approach to AI-assisted music composition.\n",
    "\n",
    "## Key Components\n",
    "1. State Management: Utilizes a `MusicState` class to manage the workflow's state.\n",
    "2. Language Model: Employs ChatOpenAI (GPT-4) for generating musical components.\n",
    "3. Musical Functions:\n",
    "   - Melody Generator\n",
    "   - Harmony Creator\n",
    "   - Rhythm Analyzer\n",
    "   - Style Adapter\n",
    "4. MIDI Conversion: Transforms the composition into a playable MIDI file.\n",
    "5. LangGraph Workflow: Orchestrates the composition process using a state graph.\n",
    "6. Playback Functionality: Allows for immediate playback of the generated composition.\n",
    "\n",
    "## Method\n",
    "1. The workflow begins by generating a melody based on user input.\n",
    "2. It then creates harmony to complement the melody.\n",
    "3. A rhythm is analyzed and suggested for the melody and harmony.\n",
    "4. The composition is adapted to the specified musical style.\n",
    "5. The final composition is converted to MIDI format.\n",
    "6. The generated MIDI file can be played back using pygame.\n",
    "\n",
    "The entire process is orchestrated using LangGraph, which manages the flow of information between different components and ensures that each step builds upon the previous ones.\n",
    "\n",
    "## Conclusion\n",
    "This AI Music Compositor demonstrates the potential of combining language models with structured workflows to create musical compositions. By breaking down the composition process into discrete steps and leveraging the power of AI, we can generate unique musical pieces based on simple user inputs. This approach opens up new possibilities for AI-assisted creativity in music production and composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/music_composer_agent_langgraph.svg\" alt=\"tts poem generator agent langgraph\" style=\"width:50%; height:auto;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all necessary modules and libraries for the AI Music Collaborator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import music21\n",
    "import pygame\n",
    "import tempfile\n",
    "import os\n",
    "import random\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables and set OpenAI API key\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Definition\n",
    "\n",
    "Define the MusicState class to hold the workflow's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicState(TypedDict):\n",
    "    \"\"\"Define the structure of the state for the music generation workflow.\"\"\"\n",
    "    musician_input: str  # User's input describing the desired music\n",
    "    melody: str          # Generated melody\n",
    "    harmony: str         # Generated harmony\n",
    "    rhythm: str          # Generated rhythm\n",
    "    style: str           # Desired musical style\n",
    "    composition: str     # Complete musical composition\n",
    "    midi_file: str       # Path to the generated MIDI file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Initialization\n",
    "\n",
    "Initialize the Language Model (LLM) for generating musical components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Functions\n",
    "\n",
    "Define the component functions for melody generation, harmony creation, rhythm analysis, style adaptation, and MIDI conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melody_generator(state: MusicState) -> Dict:\n",
    "    \"\"\"Generate a melody based on the user's input.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Create a melody that reflects the sentiment and style of this input: {input}. Format it in music21 notation.\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    melody = chain.invoke({\"input\": state[\"musician_input\"]})\n",
    "    return {\"melody\": melody.content}\n",
    "\n",
    "def harmony_creator(state: MusicState) -> Dict:\n",
    "    \"\"\"Create harmony for the generated melody.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Create harmony for this melody: {melody}. Represent it as a string of chords in music21 format.\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    harmony = chain.invoke({\"melody\": state[\"melody\"]})\n",
    "    return {\"harmony\": harmony.content}\n",
    "\n",
    "def rhythm_analyzer(state: MusicState) -> Dict:\n",
    "    \"\"\"Analyze and suggest a rhythm for the melody and harmony.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze and suggest a rhythm for this melody and harmony: {melody}, {harmony}. Represent it as a string of durations in music21 format.\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    rhythm = chain.invoke({\"melody\": state[\"melody\"], \"harmony\": state[\"harmony\"]})\n",
    "    return {\"rhythm\": rhythm.content}\n",
    "\n",
    "def style_adapter(state: MusicState) -> Dict:\n",
    "    \"\"\"Adapt the composition to the specified musical style.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Adapt this composition to the {style} style: Melody: {melody}, Harmony: {harmony}, Rhythm: {rhythm}. Provide the result in music21 format.\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    adapted = chain.invoke({\n",
    "        \"style\": state[\"style\"],\n",
    "        \"melody\": state[\"melody\"],\n",
    "        \"harmony\": state[\"harmony\"],\n",
    "        \"rhythm\": state[\"rhythm\"]\n",
    "    })\n",
    "    return {\"composition\": adapted.content}\n",
    "\n",
    "def midi_converter(state: MusicState) -> Dict:\n",
    "    \"\"\"Convert the composition to MIDI format and save it as a file.\"\"\"\n",
    "    # Create a new stream\n",
    "    piece = music21.stream.Score()\n",
    "\n",
    "    # Add the composition description to the stream as a text expression\n",
    "    description = music21.expressions.TextExpression(state[\"composition\"])\n",
    "    piece.append(description)\n",
    "\n",
    "    # Define a wide variety of scales and chords\n",
    "    scales = {\n",
    "        'C major': ['C', 'D', 'E', 'F', 'G', 'A', 'B'],\n",
    "        'C minor': ['C', 'D', 'Eb', 'F', 'G', 'Ab', 'Bb'],\n",
    "        'C harmonic minor': ['C', 'D', 'Eb', 'F', 'G', 'Ab', 'B'],\n",
    "        'C melodic minor': ['C', 'D', 'Eb', 'F', 'G', 'A', 'B'],\n",
    "        'C dorian': ['C', 'D', 'Eb', 'F', 'G', 'A', 'Bb'],\n",
    "        'C phrygian': ['C', 'Db', 'Eb', 'F', 'G', 'Ab', 'Bb'],\n",
    "        'C lydian': ['C', 'D', 'E', 'F#', 'G', 'A', 'B'],\n",
    "        'C mixolydian': ['C', 'D', 'E', 'F', 'G', 'A', 'Bb'],\n",
    "        'C locrian': ['C', 'Db', 'Eb', 'F', 'Gb', 'Ab', 'Bb'],\n",
    "        'C whole tone': ['C', 'D', 'E', 'F#', 'G#', 'A#'],\n",
    "        'C diminished': ['C', 'D', 'Eb', 'F', 'Gb', 'Ab', 'A', 'B'],\n",
    "    }\n",
    "\n",
    "    chords = {\n",
    "        'C major': ['C4', 'E4', 'G4'],\n",
    "        'C minor': ['C4', 'Eb4', 'G4'],\n",
    "        'C diminished': ['C4', 'Eb4', 'Gb4'],\n",
    "        'C augmented': ['C4', 'E4', 'G#4'],\n",
    "        'C dominant 7th': ['C4', 'E4', 'G4', 'Bb4'],\n",
    "        'C major 7th': ['C4', 'E4', 'G4', 'B4'],\n",
    "        'C minor 7th': ['C4', 'Eb4', 'G4', 'Bb4'],\n",
    "        'C half-diminished 7th': ['C4', 'Eb4', 'Gb4', 'Bb4'],\n",
    "        'C fully diminished 7th': ['C4', 'Eb4', 'Gb4', 'A4'],\n",
    "    }\n",
    "\n",
    "    def create_melody(scale_name, duration):\n",
    "        \"\"\"Create a melody based on a given scale.\"\"\"\n",
    "        melody = music21.stream.Part()\n",
    "        scale = scales[scale_name]\n",
    "        for _ in range(duration):\n",
    "            note = music21.note.Note(random.choice(scale) + '4')\n",
    "            note.quarterLength = 1\n",
    "            melody.append(note)\n",
    "        return melody\n",
    "\n",
    "    def create_chord_progression(duration):\n",
    "        \"\"\"Create a chord progression.\"\"\"\n",
    "        harmony = music21.stream.Part()\n",
    "        for _ in range(duration):\n",
    "            chord_name = random.choice(list(chords.keys()))\n",
    "            chord = music21.chord.Chord(chords[chord_name])\n",
    "            chord.quarterLength = 1\n",
    "            harmony.append(chord)\n",
    "        return harmony\n",
    "\n",
    "    # Parse the user input to determine scale and style\n",
    "    user_input = state['musician_input'].lower()\n",
    "    if 'minor' in user_input:\n",
    "        scale_name = 'C minor'\n",
    "    elif 'major' in user_input:\n",
    "        scale_name = 'C major'\n",
    "    else:\n",
    "        scale_name = random.choice(list(scales.keys()))\n",
    "\n",
    "    # Create a 7-second piece (7 beats at 60 BPM)\n",
    "    melody = create_melody(scale_name, 7)\n",
    "    harmony = create_chord_progression(7)\n",
    "\n",
    "    # Add a final whole note to make it exactly 8 beats (7 seconds at 60 BPM)\n",
    "    final_note = music21.note.Note(scales[scale_name][0] + '4')\n",
    "    final_note.quarterLength = 1\n",
    "    melody.append(final_note)\n",
    "    \n",
    "    final_chord = music21.chord.Chord(chords[scale_name.split()[0] + ' ' + scale_name.split()[1]])\n",
    "    final_chord.quarterLength = 1\n",
    "    harmony.append(final_chord)\n",
    "\n",
    "    # Add the melody and harmony to the piece\n",
    "    piece.append(melody)\n",
    "    piece.append(harmony)\n",
    "\n",
    "    # Set the tempo to 60 BPM\n",
    "    piece.insert(0, music21.tempo.MetronomeMark(number=60))\n",
    "\n",
    "    # Create a temporary MIDI file\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mid') as temp_midi:\n",
    "        piece.write('midi', temp_midi.name)\n",
    "    \n",
    "    return {\"midi_file\": temp_midi.name}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Construct the LangGraph workflow for the AI Music Collaborator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph\n",
    "workflow = StateGraph(MusicState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"melody_generator\", melody_generator)\n",
    "workflow.add_node(\"harmony_creator\", harmony_creator)\n",
    "workflow.add_node(\"rhythm_analyzer\", rhythm_analyzer)\n",
    "workflow.add_node(\"style_adapter\", style_adapter)\n",
    "workflow.add_node(\"midi_converter\", midi_converter)\n",
    "\n",
    "# Set the entry point of the graph\n",
    "workflow.set_entry_point(\"melody_generator\")\n",
    "\n",
    "# Add edges to connect the nodes\n",
    "workflow.add_edge(\"melody_generator\", \"harmony_creator\")\n",
    "workflow.add_edge(\"harmony_creator\", \"rhythm_analyzer\")\n",
    "workflow.add_edge(\"rhythm_analyzer\", \"style_adapter\")\n",
    "workflow.add_edge(\"style_adapter\", \"midi_converter\")\n",
    "workflow.add_edge(\"midi_converter\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Workflow\n",
    "\n",
    "Execute the AI Music Collaborator workflow to generate a musical composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'scale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusician_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a happy piano piece in C major\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRomantic era\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Invoke the workflow\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m app\u001b[38;5;241m.\u001b[39minvoke(inputs)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComposition created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMIDI file saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmidi_file\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/KTH_ML_P1/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1936\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1935\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1936\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1937\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1938\u001b[0m     config,\n\u001b[1;32m   1939\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1940\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1941\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1942\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1943\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1945\u001b[0m ):\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1947\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/anaconda3/envs/KTH_ML_P1/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1656\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1657\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1658\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1659\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1660\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1661\u001b[0m         ):\n\u001b[1;32m   1662\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/KTH_ML_P1/lib/python3.11/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     run_with_retry(\n\u001b[1;32m    168\u001b[0m         t,\n\u001b[1;32m    169\u001b[0m         retry_policy,\n\u001b[1;32m    170\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    171\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[1;32m    172\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[1;32m    173\u001b[0m         },\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/KTH_ML_P1/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/KTH_ML_P1/lib/python3.11/site-packages/langgraph/utils/runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/KTH_ML_P1/lib/python3.11/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m, in \u001b[0;36mmelody_generator\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the \u001b[39m\u001b[38;5;132;01m{scale}\u001b[39;00m\u001b[38;5;124m scale, compose a melody of \u001b[39m\u001b[38;5;132;01m{duration}\u001b[39;00m\u001b[38;5;124m bars. Please represent the melody in music21 format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m----> 7\u001b[0m melody \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmelody\u001b[39m\u001b[38;5;124m\"\u001b[39m: melody\u001b[38;5;241m.\u001b[39mcontent}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'scale'",
      "\u001b[0mDuring task with name 'melody_generator' and id '26d8476c-e654-ac33-358e-4974fbd72853'"
     ]
    }
   ],
   "source": [
    "# Define input parameters\n",
    "inputs = {\n",
    "    \"musician_input\": \"Create a happy piano piece in C major\",\n",
    "    \"style\": \"Romantic era\"\n",
    "}\n",
    "\n",
    "# Invoke the workflow\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(\"Composition created\")\n",
    "print(f\"MIDI file saved at: {result['midi_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDI Playback Function\n",
    "\n",
    "Define a function to play the generated MIDI file using pygame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create and play a melody, run the following in a new cell:\n",
      "play_midi(result['midi_file'])\n"
     ]
    }
   ],
   "source": [
    "def play_midi(midi_file_path):\n",
    "    \"\"\"Play the generated MIDI file.\"\"\"\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(midi_file_path)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Wait for playback to finish\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "    \n",
    "    # Clean up\n",
    "    pygame.mixer.quit()\n",
    "\n",
    "\n",
    "print(\"To create and play a melody, run the following in a new cell:\")\n",
    "print(\"play_midi(result['midi_file'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play the Generated Music\n",
    "\n",
    "Execute this cell to play the generated MIDI file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m play_midi(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmidi_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mplay_midi\u001b[0;34m(midi_file_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Wait for playback to finish\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pygame\u001b[38;5;241m.\u001b[39mmixer\u001b[38;5;241m.\u001b[39mmusic\u001b[38;5;241m.\u001b[39mget_busy():\n\u001b[0;32m----> 9\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mClock()\u001b[38;5;241m.\u001b[39mtick(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Clean up\u001b[39;00m\n\u001b[1;32m     12\u001b[0m pygame\u001b[38;5;241m.\u001b[39mmixer\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "play_midi(result[\"midi_file\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
